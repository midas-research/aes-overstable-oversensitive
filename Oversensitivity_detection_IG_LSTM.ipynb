{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiXzu0u_XW_m",
        "outputId": "35c76a62-bafa-4af5-d32c-4346a12b0471"
      },
      "source": [
        "!git clone https://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@github.com/SwapnilDreams100/white-box-aes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'white-box-aes'...\n",
            "remote: Enumerating objects: 1264, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (164/164), done.\u001b[K\n",
            "remote: Total 1264 (delta 134), reused 153 (delta 77), pack-reused 1018\u001b[K\n",
            "Receiving objects: 100% (1264/1264), 231.13 MiB | 22.97 MiB/s, done.\n",
            "Resolving deltas: 100% (593/593), done.\n",
            "Checking out files: 100% (228/228), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNNhDoABdLwR",
        "outputId": "9fe790e4-8c39-4dd2-e685-aadff8fcc444"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD4EY1qaXnID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "697bc448-2c75-4efa-95d6-b4709de398e7"
      },
      "source": [
        "# %%capture\n",
        "%cd /content/white-box-aes\n",
        "! pip install tensorflow==2.2.0\n",
        "! pip install see-rnn\n",
        "! pip install alibi==0.5.\n",
        "! pip install transformers\n",
        "%cd /content/white-box-aes/skipflow_clean\n",
        "!cp /content/drive/MyDrive/asap-glove.pkl ./glove/asap-glove.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/white-box-aes\n",
            "Collecting tensorflow==2.2.0\n",
            "  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.17.3)\n",
            "Collecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 46.1 MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.39.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.19.5)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 38.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.2.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (1.6.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.2.0) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.34.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0) (3.5.0)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, h5py, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.6.0\n",
            "    Uninstalling tensorboard-2.6.0:\n",
            "      Successfully uninstalled tensorboard-2.6.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0\n",
            "Collecting see-rnn\n",
            "  Downloading see_rnn-1.15.1-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from see-rnn) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from see-rnn) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->see-rnn) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->see-rnn) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->see-rnn) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->see-rnn) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->see-rnn) (1.15.0)\n",
            "Installing collected packages: see-rnn\n",
            "Successfully installed see-rnn-1.15.1\n",
            "Collecting alibi==0.5.6\n",
            "  Downloading alibi-0.5.6-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (1.4.1)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.7.1\n",
            "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
            "\u001b[K     |████████████████████████████████| 115 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting shap!=0.38.1,<0.39.0,>=0.36.0\n",
            "  Downloading shap-0.37.0.tar.gz (326 kB)\n",
            "\u001b[K     |████████████████████████████████| 326 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy[lookups]<4.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (2.2.4)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.2 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (3.7.4.3)\n",
            "Requirement already satisfied: scikit-learn<0.25.0,>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (0.22.2.post1)\n",
            "Requirement already satisfied: tensorflow<2.5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (2.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (1.19.5)\n",
            "Requirement already satisfied: scikit-image!=0.17.1,<0.19,>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (0.16.2)\n",
            "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (1.1.5)\n",
            "Collecting attrs<21.0.0,>=19.2.0\n",
            "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow<9.0,>=5.4.1 in /usr/local/lib/python3.7/dist-packages (from alibi==0.5.6) (7.1.2)\n",
            "Collecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi==0.5.6) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi==0.5.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi==0.5.6) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<4.0.0,>=3.0.0->alibi==0.5.6) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib<4.0.0,>=3.0.0->alibi==0.5.6) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0.0,>=0.23.3->alibi==0.5.6) (2018.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi==0.5.6) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi==0.5.6) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi==0.5.6) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.21.0->alibi==0.5.6) (3.0.4)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.19,>=0.14.2->alibi==0.5.6) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.19,>=0.14.2->alibi==0.5.6) (2.6.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image!=0.17.1,<0.19,>=0.14.2->alibi==0.5.6) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25.0,>=0.20.2->alibi==0.5.6) (1.0.1)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap!=0.38.1,<0.39.0,>=0.36.0->alibi==0.5.6) (4.62.0)\n",
            "Collecting slicer==0.0.3\n",
            "  Downloading slicer-0.0.3-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap!=0.38.1,<0.39.0,>=0.36.0->alibi==0.5.6) (0.51.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (2.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (0.4.1)\n",
            "Collecting spacy-lookups-data<0.2.0,>=0.0.5\n",
            "  Downloading spacy_lookups_data-0.1.0.tar.gz (28.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 28.0 MB 61 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy[lookups]<4.0.0,>=2.0.0->alibi==0.5.6) (3.5.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (0.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.12.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.6.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.39.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (0.37.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (0.3.3)\n",
            "Requirement already satisfied: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (2.2.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (2.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (0.4.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow<2.5.0,>=2.0.0->alibi==0.5.6) (3.1.1)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap!=0.38.1,<0.39.0,>=0.36.0->alibi==0.5.6) (0.34.0)\n",
            "Building wheels for collected packages: shap, spacy-lookups-data\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.37.0-cp37-cp37m-linux_x86_64.whl size=465072 sha256=272150d8c33579c7ea9c9f9e62095d8a5640c06eb052f4928a81cdb846a5defa\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/b8/18/2c0a6105152e62dd9a7cf47b5110b9cedb0c8739babdef64b7\n",
            "  Building wheel for spacy-lookups-data (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-lookups-data: filename=spacy_lookups_data-0.1.0-py2.py3-none-any.whl size=28052157 sha256=a4d69590f8a91afe718272862949e260243906f4180d33217807d6b6a8110b38\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/09/83/36dd0224ce32dcdf5e218b36362235ca2e50cece60a966ae1b\n",
            "Successfully built shap spacy-lookups-data\n",
            "Installing collected packages: spacy-lookups-data, soupsieve, slicer, shap, beautifulsoup4, attrs, alibi\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 21.2.0\n",
            "    Uninstalling attrs-21.2.0:\n",
            "      Successfully uninstalled attrs-21.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed alibi-0.5.6 attrs-20.3.0 beautifulsoup4-4.9.3 shap-0.37.0 slicer-0.0.3 soupsieve-2.2.1 spacy-lookups-data-0.1.0\n",
            "/content/white-box-aes/skipflow_clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV1fmRP7mNU8",
        "outputId": "850b295a-cd22-4b6e-c8f2-148440e48b85"
      },
      "source": [
        "%cd /content/white-box-aes/skipflow_clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/white-box-aes/skipflow_clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQKef6VqRxmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8daf4e9-c626-4905-99b5-cd6ac3d89ae6"
      },
      "source": [
        "%cd /content/white-box-aes/skipflow_clean\n",
        "import argparse\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from data import preprocess, get_tokenizer, load_data, load_pickle_glove, zip_normalize\n",
        "from model import MAX_SEQUENCE_LENGTH, get_saved_attacker\n",
        "import pandas as pd\n",
        "import tensorflow.keras as keras\n",
        "# import keras\n",
        "from utils import gen_adv, get_batch_grads, hotflip_attack, top_candidates\n",
        "import os\n",
        "\n",
        "args = argparse.Namespace(\n",
        "    prompt=8,\n",
        "    mode=0,\n",
        "    target=\"stats.csv\",\n",
        "    size=128,\n",
        "    batch=64,\n",
        "    epochs=4,\n",
        "    num=3,\n",
        "    beam=3\n",
        ")\n",
        "\n",
        "ROOT = Path(\"./\")\n",
        "GLOVE = \"glove\"\n",
        "DATA = \"data\"\n",
        "GLOVE_PICKLE_FILE = \"asap-glove.pkl\"\n",
        "DATA_FILE = \"training_set_rel3.tsv\"\n",
        "prompts = [args.prompt]\n",
        "WEIGHTS = \"weights\"\n",
        "\n",
        "# Implement Logging\n",
        "logging.basicConfig(\n",
        "    filename=\"triggers.log\",\n",
        "    filemode=\"a+\",\n",
        "    format=\"%(asctime)s - %(message)s\",\n",
        "    datefmt=\"%d-%b-%y %H:%M:%S\",\n",
        "    level=logging.DEBUG,\n",
        ")\n",
        "\n",
        "glove_emb = load_pickle_glove(\n",
        "    glove_path=ROOT / GLOVE, glove_pickle_file=GLOVE_PICKLE_FILE\n",
        ")\n",
        "logging.info(\"Loaded Glove Vectors\")\n",
        "\n",
        "scores, essays = load_data(data_path=ROOT / DATA, data_file=DATA_FILE, prompts=prompts)\n",
        "_, all_essays = load_data(\n",
        "    data_path=ROOT / DATA, data_file=DATA_FILE, prompts=list(range(1, 8))\n",
        ")\n",
        "logging.info(\"Loaded Data\")\n",
        "\n",
        "old_tokenizer, new_tokenizer = get_tokenizer(essays), get_tokenizer(all_essays)\n",
        "logging.info(\"Loaded Tokenizer\")\n",
        "\n",
        "new_essays = preprocess(essays, new_tokenizer, MAX_SEQUENCE_LENGTH=MAX_SEQUENCE_LENGTH)\n",
        "new_essays, new_scores = zip_normalize([new_essays], [scores], prompts)\n",
        "logging.info(\"Preprocessed Data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/white-box-aes/skipflow_clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tciBnkDCeclX"
      },
      "source": [
        "model = get_saved_attacker(\n",
        "    new_tokenizer=new_tokenizer,\n",
        "    old_tokenizer=old_tokenizer,\n",
        "    glove_emb=glove_emb,\n",
        "    weights_path=ROOT / WEIGHTS / (\"%d_weights.h5\" % args.prompt),\n",
        ")\n",
        "logging.info(\"Loaded Model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKtoA8xdehPd"
      },
      "source": [
        "# model.predict()\n",
        "x_att, y_att = gen_adv(\n",
        "        new_essays[: args.size], new_tokenizer, args.mode, 'justice'.split()\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvR_JfxnzjG3",
        "outputId": "06d62a77-f9a1-4d15-8b79-e54e116adab9"
      },
      "source": [
        "model.predict(x_att[4:5])*30"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17.899944]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyamPAQkhPWV"
      },
      "source": [
        "from alibi.explainers import IntegratedGradients\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import math\n",
        "from IPython.display import HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM4_jTjLTT5m"
      },
      "source": [
        "ig  = IntegratedGradients(model,\n",
        "                            layer= model.get_layer(index = 23),\n",
        "                            n_steps=50,\n",
        "                            method='riemann_trapezoid',\n",
        "                            internal_batch_size=100)\n",
        "\n",
        "def explain(essay):\n",
        "    attrs = get_attrs_alibi(essay)[0]\n",
        "    words,count = sequence_to_text(essay[0])\n",
        "    assert len(words[count:]) == len(attrs[count:])\n",
        "    html = visualize_token_attrs(words[count:], attrs[count:])\n",
        "    return attrs, words, count, html\n",
        "\n",
        "def get_attrs_alibi(essay = x_att[1:2]):\n",
        "    baseline = np.zeros(essay.shape)\n",
        "    baseline[0][0] = new_tokenizer.word_index['a']\n",
        "    explanation = ig.explain(essay, baselines=baseline) \n",
        "    attrs = explanation.attributions\n",
        "    attrs = attrs[0].sum(axis=2)\n",
        "    return attrs\n",
        "\n",
        "def sequence_to_text(list_of_indices):\n",
        "    count = 0\n",
        "    words = [new_tokenizer.index_word.get(ind) for ind in list_of_indices]\n",
        "    for x in words:\n",
        "      if x == None:\n",
        "        count+=1\n",
        "    return (words, count)\n",
        "    \n",
        "def visualize_token_attrs(tokens, attrs):\n",
        "    cmap='PiYG'\n",
        "    cmap_bound = np.abs(attrs).max()\n",
        "    norm = mpl.colors.Normalize(vmin=-cmap_bound, vmax=cmap_bound)\n",
        "    cmap = mpl.cm.get_cmap(cmap)\n",
        "\n",
        "    len_tokens = 0\n",
        "    html_text = \"<html><body><style type=\\\"text/css\\\"> p { display: inline-block;  width: 183pt;}</style> <p> \"\n",
        "    for i, tok in enumerate(tokens):\n",
        "        if tok is not None:\n",
        "          color = mpl.colors.rgb2hex(cmap(norm(attrs[i])))\n",
        "          html_text += \" <mark style='background-color:{}'>{}</mark>\".format(color, tok)\n",
        "    html_text+=\" </p></body></html>\"\n",
        "    return (html_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G3OeNPWRVCN"
      },
      "source": [
        "essay = x_att[4:5]\n",
        "baseline = np.zeros(essay.shape)\n",
        "baseline[0][0] = new_tokenizer.word_index['a']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWG8kv-ERYmV"
      },
      "source": [
        "explanation = ig.explain(essay, baselines=baseline) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw4r4LDX-kxe"
      },
      "source": [
        "triggers = pd.read_csv('/content/Stats.csv')\n",
        "p7_triggers = triggers[triggers['prompt'] == (args.prompt)]['trigger'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_atmJPJ6gtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ff2ab0-7c36-46ec-d868-e93f7f1fa2f2"
      },
      "source": [
        "## Calc avg sum of first 3 words of norm and attacks\n",
        "a_att = []\n",
        "a_nor = []\n",
        "i =0\n",
        "j =0 \n",
        "while j<=50 and i<=64:\n",
        "  try:\n",
        "    i+=1\n",
        "    if len(p7_triggers[i].split())<5:\n",
        "      continue\n",
        "    x_att, y_att = gen_adv(\n",
        "          new_essays[: args.size], new_tokenizer, args.mode, p7_triggers[i].split()\n",
        "      )\n",
        "    a,_,c,html = explain(new_essays[i:i+1])\n",
        "    a1 = a[c:]\n",
        "    a,_,c,html = explain(x_att[i:i+1])\n",
        "    a2 = a[c:]\n",
        "    # a_nor+=abs(sum(a1[:3]))\n",
        "    # a_att+=abs(sum(a2[:3]))\n",
        "    a_nor.extend(a1[:3])\n",
        "    a_att.extend(a2[:3])\n",
        "    print(j)\n",
        "    j+=1\n",
        "  except Exception as e:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sd-jBLmzpuWr"
      },
      "source": [
        "# model(x_att[2:3]).numpy()[0][0]*30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMcdnr37qjW6"
      },
      "source": [
        "# x_att, y_att = gen_adv(\n",
        "#         new_essays[: 3], new_tokenizer, args.mode, p7_triggers[14].split()\n",
        "#         # new_essays[: 3], new_tokenizer, args.mode, \"justice justice justice\".split()\n",
        "#     )\n",
        "# # b = new_essays[2:3]\n",
        "# b = x_att[2:3]\n",
        "# _,_,_,html = explain(b)\n",
        "# print(y_att[2]*30)\n",
        "# HTML(html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upcCpm5mKmw3"
      },
      "source": [
        "## MODELLING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsFbjzlZNy9N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "5cbcc7d8-548d-4cfe-fa0c-ff82daa26813"
      },
      "source": [
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "random.seed(42)\n",
        "training_set = []\n",
        "for r in range(len(new_essays)):\n",
        "  flag = True\n",
        "  while flag == True: \n",
        "    try:\n",
        "      trig_int = random.randint(0,len(p7_triggers)-1)\n",
        "      x_att, y_att = gen_adv(\n",
        "                new_essays, new_tokenizer, args.mode, p7_triggers[trig_int].split()\n",
        "            )\n",
        "      flag= False\n",
        "    except Exception as e:\n",
        "      continue\n",
        "  #normal\n",
        "  train = {}\n",
        "  a,_,c,_ = explain(new_essays[r:r+1])\n",
        "  a = a[c:]\n",
        "  train['attr_1'] = a[0]\n",
        "  train['attr_2'] = a[1]\n",
        "  train['attr_3'] = a[2]\n",
        "  train['result'] = 0\n",
        "  training_set.append(train)\n",
        "  \n",
        "  #attack\n",
        "  a,_,c,_ = explain(x_att[r:r+1])\n",
        "  a = a[c:]\n",
        "  train = {}\n",
        "  train['attr_1'] = a[0]\n",
        "  train['attr_2'] = a[1]\n",
        "  train['attr_3'] = a[2]\n",
        "  train['result'] = 1\n",
        "  training_set.append(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e748b51863b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m#attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m   \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m   \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-86118da58958>\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(essay)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_attrs_alibi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-86118da58958>\u001b[0m in \u001b[0;36mget_attrs_alibi\u001b[0;34m(essay)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbaseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mexplanation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0messay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplanation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/alibi/explainers/integrated_gradients.py\u001b[0m in \u001b[0;36mexplain\u001b[0;34m(self, X, baselines, target)\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                     grad_b = _gradients_layer(self.model, self.layer[layer_idx],\n\u001b[0;32m--> 557\u001b[0;31m                                               orig_calls[layer_idx], paths_b, target_b)\n\u001b[0m\u001b[1;32m    558\u001b[0m                     \u001b[0mgrads_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/alibi/explainers/integrated_gradients.py\u001b[0m in \u001b[0;36m_gradients_layer\u001b[0;34m(model, layer, orig_call, x, target)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1048\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_aggregate_grads\u001b[0;34m(gradients)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     assert all(isinstance(g, (ops.Tensor, ops.IndexedSlices))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DGiw1CATaws"
      },
      "source": [
        "train_df = pd.DataFrame(training_set)\n",
        "train_df['attr_1'] = train_df['attr_1'].abs()\n",
        "train_df['attr_2'] = train_df['attr_2'].abs()\n",
        "train_df['attr_3'] = train_df['attr_3'].abs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_nqnPx66tNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "0957e830-aea8-4233-a2c9-7518c312d4ee"
      },
      "source": [
        "train_df.to_csv('/content/p7_3attr_examples.csv', index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4db1b196e9f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/p7_3attr_examples.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Yg28y9iO79iZ",
        "outputId": "eb6e9157-a2a5-4b88-8181-206ab3421366"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/content/p'+str(args.prompt)+'_3attr_examples.csv')\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attr_1</th>\n",
              "      <th>attr_2</th>\n",
              "      <th>attr_3</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001659</td>\n",
              "      <td>0.001960</td>\n",
              "      <td>0.000777</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003547</td>\n",
              "      <td>0.002711</td>\n",
              "      <td>0.002670</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000787</td>\n",
              "      <td>0.000909</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004973</td>\n",
              "      <td>0.003547</td>\n",
              "      <td>0.002135</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000276</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     attr_1    attr_2    attr_3  result\n",
              "0  0.001659  0.001960  0.000777       0\n",
              "1  0.003547  0.002711  0.002670       1\n",
              "2  0.000787  0.000909  0.000439       0\n",
              "3  0.004973  0.003547  0.002135       1\n",
              "4  0.000000  0.000276  0.000217       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSMqtGU2zOaF"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_df.drop('result',axis = 1), train_df['result'], test_size = 0.2, random_state= 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vfgNRhkzPeV"
      },
      "source": [
        "X_train = X_train.to_numpy().reshape(-1, 1, 3)\n",
        "X_test = X_test.to_numpy().reshape(-1, 1, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8SWppSjKmT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fc2f91-4c4a-42de-db4e-0e472d9e573a"
      },
      "source": [
        "from  tensorflow.keras.models import Sequential\n",
        "from  tensorflow.keras.layers import Dense\n",
        "from  tensorflow.keras.layers import LSTM\n",
        "from  tensorflow.keras.callbacks import EarlyStopping\n",
        "from  tensorflow.keras.optimizers import Adam\n",
        "from  tensorflow.keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(1,3)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "adam = Adam(lr=0.1)\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy', f1, precision, recall])\n",
        "# fit model\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0.01, patience = 50)\n",
        "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_split=0.2, callbacks= [es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 83ms/step - loss: 0.7017 - accuracy: 0.5011 - f1: 0.4993 - precision: 0.3750 - recall: 0.7500 - val_loss: 0.6933 - val_accuracy: 0.4828 - val_f1: 0.6543 - val_precision: 0.4880 - val_recall: 1.0000\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6968 - accuracy: 0.4924 - f1: 0.1689 - precision: 0.1281 - recall: 0.2500 - val_loss: 0.6995 - val_accuracy: 0.4828 - val_f1: 0.6543 - val_precision: 0.4880 - val_recall: 1.0000\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.6994 - accuracy: 0.4816 - f1: 0.4915 - precision: 0.3662 - recall: 0.7500 - val_loss: 0.6925 - val_accuracy: 0.5172 - val_f1: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6929 - accuracy: 0.5011 - f1: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.6900 - val_accuracy: 0.4828 - val_f1: 0.6543 - val_precision: 0.4880 - val_recall: 1.0000\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6912 - accuracy: 0.5639 - f1: 0.6196 - precision: 0.4943 - recall: 0.8750 - val_loss: 0.6818 - val_accuracy: 0.5216 - val_f1: 0.0175 - val_precision: 0.5000 - val_recall: 0.0089\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.6775 - accuracy: 0.5087 - f1: 0.3780 - precision: 0.6263 - recall: 0.5076 - val_loss: 0.6475 - val_accuracy: 0.5302 - val_f1: 0.0508 - val_precision: 0.5000 - val_recall: 0.0268\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.6103 - accuracy: 0.7056 - f1: 0.5765 - precision: 0.8309 - recall: 0.6391 - val_loss: 0.5533 - val_accuracy: 0.5129 - val_f1: 0.6684 - val_precision: 0.5040 - val_recall: 1.0000\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.7587 - f1: 0.7551 - precision: 0.8691 - recall: 0.7797 - val_loss: 0.2189 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2556 - accuracy: 0.9188 - f1: 0.9090 - precision: 0.9299 - recall: 0.9112 - val_loss: 0.2606 - val_accuracy: 0.8836 - val_f1: 0.8926 - val_precision: 0.8061 - val_recall: 1.0000\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2458 - accuracy: 0.9156 - f1: 0.8709 - precision: 0.9263 - recall: 0.8689 - val_loss: 0.0952 - val_accuracy: 0.9741 - val_f1: 0.9739 - val_precision: 0.9492 - val_recall: 1.0000\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2796 - accuracy: 0.9026 - f1: 0.9144 - precision: 0.8997 - recall: 0.9506 - val_loss: 0.0792 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1732 - accuracy: 0.9416 - f1: 0.9395 - precision: 0.9663 - recall: 0.9256 - val_loss: 0.0619 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1012 - accuracy: 0.9838 - f1: 0.9852 - precision: 0.9728 - recall: 0.9980 - val_loss: 0.0496 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1008 - accuracy: 0.9848 - f1: 0.9859 - precision: 0.9744 - recall: 0.9982 - val_loss: 0.0635 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1113 - accuracy: 0.9773 - f1: 0.9767 - precision: 0.9601 - recall: 0.9947 - val_loss: 0.1729 - val_accuracy: 0.9052 - val_f1: 0.8922 - val_precision: 0.9891 - val_recall: 0.8125\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1611 - accuracy: 0.9556 - f1: 0.9526 - precision: 0.9556 - recall: 0.9546 - val_loss: 0.0453 - val_accuracy: 0.9914 - val_f1: 0.9912 - val_precision: 0.9828 - val_recall: 1.0000\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1134 - accuracy: 0.9729 - f1: 0.9760 - precision: 0.9666 - recall: 0.9865 - val_loss: 0.0468 - val_accuracy: 0.9914 - val_f1: 0.9912 - val_precision: 0.9828 - val_recall: 1.0000\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1024 - accuracy: 0.9848 - f1: 0.9861 - precision: 0.9799 - recall: 0.9926 - val_loss: 0.0798 - val_accuracy: 0.9784 - val_f1: 0.9782 - val_precision: 0.9573 - val_recall: 1.0000\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1219 - accuracy: 0.9773 - f1: 0.9763 - precision: 0.9633 - recall: 0.9903 - val_loss: 0.0984 - val_accuracy: 0.9698 - val_f1: 0.9697 - val_precision: 0.9412 - val_recall: 1.0000\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1161 - accuracy: 0.9784 - f1: 0.9717 - precision: 0.9556 - recall: 0.9903 - val_loss: 0.0439 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1166 - accuracy: 0.9773 - f1: 0.9798 - precision: 0.9716 - recall: 0.9885 - val_loss: 0.0592 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.9827 - f1: 0.9849 - precision: 0.9743 - recall: 0.9961 - val_loss: 0.0745 - val_accuracy: 0.9871 - val_f1: 0.9865 - val_precision: 0.9909 - val_recall: 0.9821\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1254 - accuracy: 0.9784 - f1: 0.9809 - precision: 0.9779 - recall: 0.9849 - val_loss: 0.0450 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1221 - accuracy: 0.9740 - f1: 0.9723 - precision: 0.9701 - recall: 0.9756 - val_loss: 0.0725 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1188 - accuracy: 0.9762 - f1: 0.9792 - precision: 0.9702 - recall: 0.9890 - val_loss: 0.0663 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1070 - accuracy: 0.9848 - f1: 0.9822 - precision: 0.9696 - recall: 0.9957 - val_loss: 0.0581 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1106 - accuracy: 0.9794 - f1: 0.9815 - precision: 0.9778 - recall: 0.9858 - val_loss: 0.0544 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.9794 - f1: 0.9809 - precision: 0.9735 - recall: 0.9892 - val_loss: 0.0533 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1137 - accuracy: 0.9751 - f1: 0.9732 - precision: 0.9698 - recall: 0.9781 - val_loss: 0.0445 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1003 - accuracy: 0.9784 - f1: 0.9809 - precision: 0.9719 - recall: 0.9903 - val_loss: 0.0485 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1079 - accuracy: 0.9827 - f1: 0.9755 - precision: 0.9729 - recall: 0.9788 - val_loss: 0.0606 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1523 - accuracy: 0.9632 - f1: 0.9643 - precision: 0.9564 - recall: 0.9750 - val_loss: 0.1966 - val_accuracy: 0.9267 - val_f1: 0.9296 - val_precision: 0.8687 - val_recall: 1.0000\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1395 - accuracy: 0.9719 - f1: 0.9679 - precision: 0.9519 - recall: 0.9867 - val_loss: 0.0622 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1317 - accuracy: 0.9686 - f1: 0.9711 - precision: 0.9669 - recall: 0.9767 - val_loss: 0.0633 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1305 - accuracy: 0.9784 - f1: 0.9769 - precision: 0.9669 - recall: 0.9880 - val_loss: 0.0755 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1218 - accuracy: 0.9773 - f1: 0.9795 - precision: 0.9699 - recall: 0.9900 - val_loss: 0.0536 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1074 - accuracy: 0.9773 - f1: 0.9766 - precision: 0.9736 - recall: 0.9805 - val_loss: 0.0595 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.9719 - f1: 0.9717 - precision: 0.9611 - recall: 0.9837 - val_loss: 0.0899 - val_accuracy: 0.9698 - val_f1: 0.9697 - val_precision: 0.9412 - val_recall: 1.0000\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1068 - accuracy: 0.9784 - f1: 0.9806 - precision: 0.9695 - recall: 0.9925 - val_loss: 0.0733 - val_accuracy: 0.9784 - val_f1: 0.9782 - val_precision: 0.9573 - val_recall: 1.0000\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1141 - accuracy: 0.9805 - f1: 0.9795 - precision: 0.9728 - recall: 0.9872 - val_loss: 0.0749 - val_accuracy: 0.9784 - val_f1: 0.9782 - val_precision: 0.9573 - val_recall: 1.0000\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1217 - accuracy: 0.9794 - f1: 0.9813 - precision: 0.9759 - recall: 0.9877 - val_loss: 0.1404 - val_accuracy: 0.9526 - val_f1: 0.9532 - val_precision: 0.9106 - val_recall: 1.0000\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1225 - accuracy: 0.9816 - f1: 0.9812 - precision: 0.9763 - recall: 0.9869 - val_loss: 0.0992 - val_accuracy: 0.9655 - val_f1: 0.9655 - val_precision: 0.9333 - val_recall: 1.0000\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1158 - accuracy: 0.9751 - f1: 0.9775 - precision: 0.9745 - recall: 0.9815 - val_loss: 0.0545 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0970 - accuracy: 0.9848 - f1: 0.9862 - precision: 0.9808 - recall: 0.9918 - val_loss: 0.0536 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1015 - accuracy: 0.9848 - f1: 0.9799 - precision: 0.9710 - recall: 0.9901 - val_loss: 0.0491 - val_accuracy: 0.9914 - val_f1: 0.9912 - val_precision: 0.9828 - val_recall: 1.0000\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1040 - accuracy: 0.9827 - f1: 0.9813 - precision: 0.9722 - recall: 0.9912 - val_loss: 0.0551 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1131 - accuracy: 0.9784 - f1: 0.9759 - precision: 0.9776 - recall: 0.9757 - val_loss: 0.0869 - val_accuracy: 0.9871 - val_f1: 0.9865 - val_precision: 0.9909 - val_recall: 0.9821\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1290 - accuracy: 0.9762 - f1: 0.9790 - precision: 0.9713 - recall: 0.9877 - val_loss: 0.0488 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1226 - accuracy: 0.9762 - f1: 0.9782 - precision: 0.9743 - recall: 0.9831 - val_loss: 0.0534 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1270 - accuracy: 0.9751 - f1: 0.9772 - precision: 0.9715 - recall: 0.9839 - val_loss: 0.0556 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0985 - accuracy: 0.9805 - f1: 0.9832 - precision: 0.9751 - recall: 0.9920 - val_loss: 0.0484 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9848 - f1: 0.9866 - precision: 0.9808 - recall: 0.9928 - val_loss: 0.0554 - val_accuracy: 0.9957 - val_f1: 0.9956 - val_precision: 0.9912 - val_recall: 1.0000\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0984 - accuracy: 0.9773 - f1: 0.9791 - precision: 0.9721 - recall: 0.9865 - val_loss: 0.0531 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0981 - accuracy: 0.9838 - f1: 0.9848 - precision: 0.9804 - recall: 0.9893 - val_loss: 0.0482 - val_accuracy: 0.9871 - val_f1: 0.9868 - val_precision: 0.9740 - val_recall: 1.0000\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1022 - accuracy: 0.9816 - f1: 0.9826 - precision: 0.9755 - recall: 0.9903 - val_loss: 0.0737 - val_accuracy: 0.9784 - val_f1: 0.9782 - val_precision: 0.9573 - val_recall: 1.0000\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1021 - accuracy: 0.9794 - f1: 0.9787 - precision: 0.9760 - recall: 0.9820 - val_loss: 0.0648 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1121 - accuracy: 0.9773 - f1: 0.9757 - precision: 0.9658 - recall: 0.9865 - val_loss: 0.0584 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1032 - accuracy: 0.9794 - f1: 0.9775 - precision: 0.9712 - recall: 0.9847 - val_loss: 0.0687 - val_accuracy: 0.9828 - val_f1: 0.9825 - val_precision: 0.9658 - val_recall: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f27b6cadd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLDUhC206qpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06e5a70c-85de-4277-ad0a-14a0ce2e1d5d"
      },
      "source": [
        "model.save('/content/drive/MyDrive/IG RESULTS/ATTACK_MODELS/p2_3w_90val')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/IG RESULTS/ATTACK_MODELS/p2_3w_90val/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgEZr2PhkLx2"
      },
      "source": [
        "model.load('/content/drive/MyDrive/IG RESULTS/ATTACK_MODELS/p7_3w_')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHyTRR7TjJ6W"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXyoKTt8sYku"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}